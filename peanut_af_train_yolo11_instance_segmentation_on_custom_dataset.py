# -*- coding: utf-8 -*-
"""6 peanut-af train-yolo11-instance-segmentation-on-custom-dataset.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZEScbfl1e4WswIs9hnUR5hO-HGh_FWMb

#  Train  Segmentation on the Dataset

## Setup
"""

!nvidia-smi

"""**NOTE:** To make it easier for us to manage datasets, images and models we create a `HOME` constant."""

import os
HOME = os.getcwd()
print(HOME)

"""## Install  Ultralytics"""

# Commented out IPython magic to ensure Python compatibility.
# %pip install ultralytics supervision roboflow
import ultralytics
ultralytics.checks()

"""**NOTE:** Result annotated image got saved in `{HOME}/runs/detect/predict/`. Let's display it.

**NOTE:** The obtained `result` object stores information about the location, classes, and confidence levels of the detected objects.

**NOTE:** YOLO11 can be easily integrated with `supervision` using the familiar `from_ultralytics` connector.

## Fine-tune on custom dataset
"""

!pip install roboflow

from roboflow import Roboflow
rf = Roboflow(api_key="qpPq1VHvkPZnfWt3s5iK")
project = rf.workspace("fafu-jaxfw").project("peanuts-af-segmentation")
version = project.version(6)
dataset = version.download("yolov11")

"""## Custom Training

**NOTE:** The results of the completed training are saved in `{HOME}/runs/detect/train/`. Let's examine them.
"""

from google.colab import drive
drive.mount('/content/gdrive')

"""## Custom Training

For traning results saving
"""

import shutil
import os

source_directory = '/content/runs/segment'
destination_directory = '/content/gdrive/MyDrive/Peanut_AF/train'  # Use the existing directory as the parent

# Create the destination directory if it doesn't exist
if not os.path.exists(destination_directory):
    os.makedirs(destination_directory)

# Copy the contents of the source directory into the destination directory
for item in os.listdir(source_directory):
    source_item = os.path.join(source_directory, item)
    destination_item = os.path.join(destination_directory, item)
    if os.path.isdir(source_item):
        shutil.copytree(source_item, destination_item)
    else:
        shutil.copy2(source_item, destination_item)

from ultralytics import YOLO
from IPython.display import Image, display as IPyImage

"""## Validate fine-tuned model

# Post processing for My task âœˆ
"""

import os
import numpy as np
import matplotlib.pyplot as plt
from scipy.ndimage import label
from PIL import Image
from IPython.display import display as IPyImage
# Define the folder containing images and the output folder
image_folder = "/content/gdrive/MyDrive/Peanut_AF/show"
output_folder = "/content/gdrive/MyDrive/Peanut_AF/labeled_results"
# Load the YOLO model
model_path = "/content/gdrive/MyDrive/Peanut_AF/train/train/weights/best.pt"
model = YOLO(model_path)

# Create the output folder if it doesn't exist
os.makedirs(output_folder, exist_ok=True)


# Define your model and paths
# Assuming `model` and its prediction logic are already defined (e.g., YOLO model)

# Process each image in the image folder
for filename in os.listdir(image_folder):
    if filename.lower().endswith(('.png', '.jpg', '.jpeg')):  # Process only image files
        image_path = os.path.join(image_folder, filename)
        print(f"Processing: {image_path}")

        # Load the image and get the segmentation results (mask_array)
        image = Image.open(image_path)
        image_array = np.array(image)

        # Perform segmentation inference using the YOLO model (or your model)
        results = model.predict(source=image_path)

        for result in results:
            if hasattr(result, 'masks') and result.masks is not None:
                # Get the masks from the result
                segmentation_masks = result.masks.data.cpu().numpy()  # Masks as NumPy array

                # Combine all instance masks into a single mask array
                mask_array = np.zeros_like(segmentation_masks, dtype=np.uint8)
                for i, mask in enumerate(segmentation_masks):
                    mask_array[i] = mask

                # Sum the masks along axis 0 to combine multiple instance masks into a single mask
                combined_mask = mask_array.sum(axis=0)  # Sum across all instance masks

                # Create a labeled mask from the combined mask
                labeled_mask, num_peanuts = label(combined_mask)  # Label the connected components

                # Show the labeled mask with distinct colors for each instance
                plt.figure(figsize=(10, 10))
                plt.imshow(labeled_mask, cmap='tab20')  # Use 'tab20' colormap for distinct colors
                plt.title(f"Detected Peanuts: {num_peanuts}")

                # Save the labeled mask result to the output folder
                output_image_path = os.path.join(output_folder, f"labeled_{filename}")
                plt.savefig(output_image_path)
                plt.close()  # Close the plot to free memory

                print(f"Saved labeled image to: {output_image_path}")

                # Display the image inline
                display(IPyImage(filename=output_image_path))
            else:
                print(f"No segmentation masks found for image: {filename}")

import os
import numpy as np
import matplotlib.pyplot as plt
from scipy.ndimage import label, distance_transform_edt
from PIL import Image
from skimage.morphology import erosion, dilation
from skimage.segmentation import watershed
from skimage.feature import peak_local_max
import cv2  # For loading images with OpenCV if needed

# ... (rest of your code)
# Define the folder containing images and the output folder
image_folder = "/content/gdrive/MyDrive/Peanut_AF/show"
output_folder = "/content/gdrive/MyDrive/Peanut_AF/labeled_results"

# Load image and get segmentation mask
image_path = os.path.join(image_folder, filename)
image = Image.open(image_path)  # Try PIL first
image_array = np.array(image)

# If PIL fails, try OpenCV
if image_array.shape == (1, 1):  # Check if it's a single pixel
  image_data = cv2.imread(image_path)
  if image_data is not None:
    image_array = cv2.cvtColor(image_data, cv2.COLOR_BGR2RGB)  # Convert to RGB if necessary
    image = Image.fromarray(image_array)

# Create the output folder if it doesn't exist
os.makedirs(output_folder, exist_ok=True)

# Process each image in the image folder
for filename in os.listdir(image_folder):
    if filename.lower().endswith(('.png', '.jpg', '.jpeg')):  # Process only image files
        image_path = os.path.join(image_folder, filename)
        print(f"Processing: {image_path}")

        # Load the image and get the segmentation results (mask_array)
        image = Image.open(image_path)
        image_array = np.array(image)

        # Perform segmentation inference using the YOLO model (or your model)
        results = model.predict(source=image_path)  # Replace with your model's prediction logic

        for result in results:
            if hasattr(result, 'masks') and result.masks is not None:
                # Get the masks from the result
                segmentation_masks = result.masks.data.cpu().numpy()  # Masks as NumPy array

                # Combine all instance masks into a single mask array
                mask_array = np.zeros_like(segmentation_masks, dtype=np.uint8)
                for i, mask in enumerate(segmentation_masks):
                    mask_array[i] = mask

                # Sum the masks along axis 0 to combine multiple instance masks into a single mask
                combined_mask = mask_array.sum(axis=0)  # Sum across all instance masks




                # ... (rest of your code)

                # ... (watershed segmentation logic)
                distance = distance_transform_edt(combined_mask)
                local_maxima = distance > np.percentile(distance, 90)  # Adjust percentile as needed
                markers = label(local_maxima)[0]

                # Ensure markers and mask have compatible shapes
                markers = markers.reshape(combined_mask.shape)

                labels = watershed(-distance, markers, mask=combined_mask)



                # Print shapes for debugging
                print("Distance Transform Shape:", distance.shape)
                print("Local Maxima Shape:", local_maxima.shape)
                print("Markers Shape:", markers.shape)
                print("Combined Mask Shape:", combined_mask.shape)


                # ... (rest of your code)

                # Show the labeled mask with distinct colors for each instance
                plt.figure(figsize=(10, 10))
                plt.imshow(labels, cmap='tab20')  # Use 'tab20' colormap for distinct colors
                plt.title(f"Detected Peanuts: {len(np.unique(labels)) - 1}")
                plt.show()

                # Save the labeled mask result to the output folder
                output_image_path = os.path.join(output_folder, f"labeled_{filename}")
                plt.savefig(output_image_path)
                plt.close()  # Close the plot to free memory

            else:
                print(f"No segmentation masks found for image: {filename}")

import os
import numpy as np
import matplotlib.pyplot as plt
from scipy.ndimage import label, distance_transform_edt
from PIL import Image
from skimage.morphology import erosion, dilation
from skimage.segmentation import watershed
from skimage.feature import peak_local_max
import cv2  # For loading images with OpenCV if needed
from skimage.morphology import erosion, dilation, closing

# ... (rest of your code)
# Define the folder containing images and the output folder
image_folder = "/content/gdrive/MyDrive/Peanut_AF/show"
output_folder = "/content/gdrive/MyDrive/Peanut_AF/labeled_results"

# Load image and get segmentation mask
image_path = os.path.join(image_folder, filename)
image = Image.open(image_path)  # Try PIL first
image_array = np.array(image)

# If PIL fails, try OpenCV
if image_array.shape == (1, 1):  # Check if it's a single pixel
  image_data = cv2.imread(image_path)
  if image_data is not None:
    image_array = cv2.cvtColor(image_data, cv2.COLOR_BGR2RGB)  # Convert to RGB if necessary
    image = Image.fromarray(image_array)

# Create the output folder if it doesn't exist
os.makedirs(output_folder, exist_ok=True)

# Process each image in the image folder
for filename in os.listdir(image_folder):
    if filename.lower().endswith(('.png', '.jpg', '.jpeg')):  # Process only image files
        image_path = os.path.join(image_folder, filename)
        print(f"Processing: {image_path}")

        # Load the image and get the segmentation results (mask_array)
        image = Image.open(image_path)
        image_array = np.array(image)

        # Perform segmentation inference using the YOLO model (or your model)
        results = model.predict(source=image_path)  # Replace with your model's prediction logic

        for result in results:
            if hasattr(result, 'masks') and result.masks is not None:
                # Get the masks from the result
                segmentation_masks = result.masks.data.cpu().numpy()  # Masks as NumPy array

                # Combine all instance masks into a single mask array
                mask_array = np.zeros_like(segmentation_masks, dtype=np.uint8)
                for i, mask in enumerate(segmentation_masks):
                    mask_array[i] = mask

                # Sum the masks along axis 0 to combine multiple instance masks into a single mask
                combined_mask = mask_array.sum(axis=0)  # Sum across all instance masks





                # # ... (watershed segmentation logic)
                # distance = distance_transform_edt(combined_mask)
                # local_maxima = distance > np.percentile(distance, 95)  # Adjust percentile as needed
                # markers = label(local_maxima)[0]

                # # Ensure markers and mask have compatible shapes
                # markers = markers.reshape(combined_mask.shape)

                # labels = watershed(-distance, markers, mask=combined_mask)



                # Perform watershed segmentation
                distance = distance_transform_edt(combined_mask)
                local_maxima = distance > np.percentile(distance, 95)  # Adjust percentile as needed
                #local_maxima = peak_local_max(distance, footprint=np.ones((3, 3)), min_distance=10, threshold_rel=0.5)

                markers = label(local_maxima)[0]

                # Ensure markers and mask have compatible shapes
                markers = markers.reshape(combined_mask.shape)
                # markers = np.repeat(markers, combined_mask.shape[1], axis=1)

                # Perform watershed segmentation
                labels = watershed(-distance, markers, mask=combined_mask)

                # Apply morphological closing to merge small segments
                kernel = np.ones((5, 5), np.uint8)  # Adjust kernel size as needed
                labels = closing(labels, kernel)


                # Show the labeled mask with distinct colors for each instance
                plt.figure(figsize=(10, 10))
                plt.imshow(labels, cmap='tab20')  # Use 'tab20' colormap for distinct colors
                plt.title(f"Detected Peanuts: {len(np.unique(labels)) - 1}")
                plt.show()

                # Save the labeled mask result to the output folder
                output_image_path = os.path.join(output_folder, f"labeled_{filename}")
                plt.savefig(output_image_path)
                plt.close()  # Close the plot to free memory

            else:
                print(f"No segmentation masks found for image: {filename}")



import os
import numpy as np
import matplotlib.pyplot as plt
from scipy.ndimage import label, distance_transform_edt
from PIL import Image
from skimage.morphology import erosion, dilation
from skimage.segmentation import watershed
from skimage.feature import peak_local_max
import cv2  # For loading images with OpenCV if needed
from skimage.morphology import erosion, dilation, closing

# ... (rest of your code)
# Define the folder containing images and the output folder
image_folder = "/content/gdrive/MyDrive/Peanut_AF/show"
output_folder = "/content/gdrive/MyDrive/Peanut_AF/labeled_results"

# Load image and get segmentation mask
image_path = os.path.join(image_folder, filename)
image = Image.open(image_path)  # Try PIL first
image_array = np.array(image)

# If PIL fails, try OpenCV
if image_array.shape == (1, 1):  # Check if it's a single pixel
  image_data = cv2.imread(image_path)
  if image_data is not None:
    image_array = cv2.cvtColor(image_data, cv2.COLOR_BGR2RGB)  # Convert to RGB if necessary
    image = Image.fromarray(image_array)

# Create the output folder if it doesn't exist
os.makedirs(output_folder, exist_ok=True)

# Process each image in the image folder
for filename in os.listdir(image_folder):
    if filename.lower().endswith(('.png', '.jpg', '.jpeg')):  # Process only image files
        image_path = os.path.join(image_folder, filename)
        print(f"Processing: {image_path}")

        # Load the image and get the segmentation results (mask_array)
        image = Image.open(image_path)
        image_array = np.array(image)

        # Perform segmentation inference using the YOLO model (or your model)
        results = model.predict(source=image_path)  # Replace with your model's prediction logic

        for result in results:
            if hasattr(result, 'masks') and result.masks is not None:
                # Get the masks from the result
                segmentation_masks = result.masks.data.cpu().numpy()  # Masks as NumPy array

                # Combine all instance masks into a single mask array
                mask_array = np.zeros_like(segmentation_masks, dtype=np.uint8)
                for i, mask in enumerate(segmentation_masks):
                    mask_array[i] = mask

                # Sum the masks along axis 0 to combine multiple instance masks into a single mask
                combined_mask = mask_array.sum(axis=0)  # Sum across all instance masks





                # # ... (watershed segmentation logic)
                # distance = distance_transform_edt(combined_mask)
                # local_maxima = distance > np.percentile(distance, 95)  # Adjust percentile as needed
                # markers = label(local_maxima)[0]

                # # Ensure markers and mask have compatible shapes
                # markers = markers.reshape(combined_mask.shape)

                # labels = watershed(-distance, markers, mask=combined_mask)



                # Perform watershed segmentation
                distance = distance_transform_edt(combined_mask)
                local_maxima = distance > np.percentile(distance, 95)  # Adjust percentile as needed
                #local_maxima = peak_local_max(distance, footprint=np.ones((3, 3)), min_distance=10, threshold_rel=0.5)

                markers = label(local_maxima)[0]

                # Ensure markers and mask have compatible shapes
                markers = markers.reshape(combined_mask.shape)
                # markers = np.repeat(markers, combined_mask.shape[1], axis=1)

                # Perform watershed segmentation
                labels = watershed(-distance, markers, mask=combined_mask)

                # Apply morphological closing to merge small segments
                kernel = np.ones((5, 5), np.uint8)  # Adjust kernel size as needed
                labels = closing(labels, kernel)



                # Step 1: Visualize the raw mask (optional)
                plt.figure(figsize=(10, 15))  # Adjust figure size as needed
                # Check mask shape before visualization

                if mask_array.ndim == 2:
                  plt.subplot(3, 1, 1)
                  plt.imshow(mask_array, cmap='gray')
                  plt.title(f"Raw Segmentation Mask for {filename}")
                elif mask_array.ndim == 3 and mask_array.shape[-1] == 1:
                  plt.subplot(3, 1, 1)
                  plt.imshow(mask_array[:, :, 0], cmap='gray')  # Access grayscale channel
                  plt.title(f"Raw Segmentation Mask for {filename}")
                else:
                  print(f"Warning: Unexpected mask shape {mask_array.shape}. Skipping mask visualization.")

                # Visualize raw mask
                plt.subplot(3, 1, 1)
                plt.imshow(mask_array, cmap='gray')
                plt.title(f"Raw Segmentation Mask for {filename}")

                # Step 2: Visualize instance masks (watershed segmentation result)
                plt.subplot(3, 1, 2)
                instance_colors = np.random.rand(len(np.unique(labels)) - 1, 3)  # Generate random colors
                instance_masks = np.zeros_like(labels, dtype=bool)
                for i in range(1, len(np.unique(labels))):
                  instance_masks[labels == i] = True
                plt.imshow(instance_masks, cmap='gray')
                plt.title(f"Instance Masks (Watershed Segmentation)")

                # Step 3: Visualize final labels with color coding
                plt.subplot(3, 1, 3)
                plt.imshow(labels, cmap='tab20')  # Use a colormap for different labels
                plt.title(f"Final Labels (Color-Coded)")

                plt.tight_layout()
                plt.show()


            #     # Show the labeled mask with distinct colors for each instance
            #     plt.figure(figsize=(10, 10))
            #     plt.imshow(labels, cmap='tab20')  # Use 'tab20' colormap for distinct colors
            #     plt.title(f"Detected Peanuts: {len(np.unique(labels)) - 1}")
            #     plt.show()

            #     # Save the labeled mask result to the output folder
            #     output_image_path = os.path.join(output_folder, f"labeled_{filename}")
            #     plt.savefig(output_image_path)
            #     plt.close()  # Close the plot to free memory

            # else:
            #     print(f"No segmentation masks found for image: {filename}")

import os
import numpy as np
import cv2
import matplotlib.pyplot as plt
from PIL import Image
from IPython.display import display

# Define the folder containing images and the output folder
image_folder = "/content/gdrive/MyDrive/Peanut_AF/show"
output_folder = "/content/gdrive/MyDrive/Peanut_AF/labeled_results"

# Create the output folder if it doesn't exist
os.makedirs(output_folder, exist_ok=True)

# Process each image in the image folder
for filename in os.listdir(image_folder):
    if filename.lower().endswith(('.png', '.jpg', '.jpeg')):  # Process only image files
        image_path = os.path.join(image_folder, filename)
        print(f"Processing: {image_path}")

        # Load the image and get the segmentation results (mask_array)
        image = Image.open(image_path)
        image_array = np.array(image)

        # Perform segmentation inference using the YOLO model (or your model)
        results = model.predict(source=image_path)

        for result in results:
            if hasattr(result, 'masks') and result.masks is not None:
                # Get the masks from the result
                segmentation_masks = result.masks.data.cpu().numpy()  # Masks as NumPy array

                # Combine all instance masks into a single mask array
                mask_array = np.zeros_like(segmentation_masks[0], dtype=np.uint8)
                for mask in segmentation_masks:
                    mask_array = np.logical_or(mask_array, mask).astype(np.uint8)

                # Step 1: Visualize the raw mask to ensure it is properly detected
                plt.figure(figsize=(10, 10))
                plt.imshow(mask_array, cmap='gray')
                plt.title(f"Raw Segmentation Mask for {filename}")
                plt.show()

                # Step 2: Apply connected component labeling to find separate peanuts
                num_labels, labeled_mask = cv2.connectedComponents(mask_array)

                # Step 3: Visualize the labeled mask
                plt.figure(figsize=(10, 10))
                plt.imshow(labeled_mask, cmap='tab20')  # Use 'tab20' colormap for distinct colors
                plt.title(f"Detected Peanuts: {num_labels - 1}")  # Subtract 1 to ignore background
                plt.show()

                # Save the labeled mask result to the output folder
                output_image_path = os.path.join(output_folder, f"labeled_{filename}")
                plt.savefig(output_image_path)
                plt.close()  # Close the plot to free memory

                print(f"Saved labeled image to: {output_image_path}")

                # Display the image inline
                display(IPyImage(filename=output_image_path))
            else:
                print(f"No segmentation masks found for image: {filename}")

import os
import numpy as np
import cv2
import matplotlib.pyplot as plt
from PIL import Image
from IPython.display import display

# Define the folder containing images and the output folder
image_folder = "/content/gdrive/MyDrive/Peanut_AF/show"
output_folder = "/content/gdrive/MyDrive/Peanut_AF/labeled_results"

# Create the output folder if it doesn't exist
os.makedirs(output_folder, exist_ok=True)

# Process each image in the image folder
for filename in os.listdir(image_folder):
    if filename.lower().endswith(('.png', '.jpg', '.jpeg')):  # Process only image files
        image_path = os.path.join(image_folder, filename)
        print(f"Processing: {image_path}")

        # Load the image and get the segmentation results (mask_array)
        image = Image.open(image_path)
        image_array = np.array(image)

        # Perform segmentation inference using the YOLO model (or your model)
        results = model.predict(source=image_path)

        for result in results:
            if hasattr(result, 'masks') and result.masks is not None:
                # Get the masks from the result
                segmentation_masks = result.masks.data.cpu().numpy()  # Masks as NumPy array

                # Combine all instance masks into a single mask array
                mask_array = np.zeros_like(segmentation_masks[0], dtype=np.uint8)
                for mask in segmentation_masks:
                    mask_array = np.logical_or(mask_array, mask).astype(np.uint8)

                # Step 1: Apply Morphological Operations to separate connected peanuts
                # Erosion followed by dilation to separate touching objects
                kernel = np.ones((5, 5), np.uint8)
                separated_mask = cv2.erode(mask_array, kernel, iterations=1)  # Erosion
                separated_mask = cv2.dilate(separated_mask, kernel, iterations=2)  # Dilation

                # Step 2: Apply connected component labeling to find separate peanuts
                num_labels, labeled_mask = cv2.connectedComponents(separated_mask)

                # Step 3: Visualize the labeled mask with distinct colors
                plt.figure(figsize=(8, 8))
                plt.imshow(labeled_mask, cmap='tab20')  # Use 'tab20' for distinct colors
                plt.title(f"Detected Peanuts: {num_labels - 1}")  # Subtract 1 to ignore background
                plt.show()

                # Save the labeled mask result to the output folder
                output_image_path = os.path.join(output_folder, f"labeled_{filename}")
                plt.savefig(output_image_path)
                plt.close()  # Close the plot to free memory

                print(f"Saved labeled image to: {output_image_path}")

                # Display the image inline
                display(IPyImage(filename=output_image_path))
            else:
                print(f"No segmentation masks found for image: {filename}")

import os
import numpy as np
import cv2
from PIL import Image
import matplotlib.pyplot as plt
from ultralytics import YOLO

# Define the folder containing images and the output folder
image_folder = "/content/gdrive/MyDrive/Peanut_AF/show"  # Your folder containing images
output_folder = "/content/gdrive/MyDrive/Peanut_AF/labeled_results"  # Folder to save labeled results

# Create the output folder if it doesn't exist
os.makedirs(output_folder, exist_ok=True)

# Load the YOLO model
model_path = "/content/gdrive/MyDrive/Peanut_AF/train/train/weights/best.pt"
model = YOLO(model_path)

# Define a threshold for the minimum area to consider a valid peanut
MIN_AREA = 500  # Minimum area to consider a valid peanut (adjust based on your dataset)

# Process each image in the image folder
for filename in os.listdir(image_folder):
    if filename.lower().endswith(('.png', '.jpg', '.jpeg')):  # Process only image files
        image_path = os.path.join(image_folder, filename)
        print(f"Processing: {image_path}")

        # Run inference on the image to get the segmentation masks
        results = model.predict(source=image_path)

        for result in results:
            # Extract the masks (each mask corresponds to a detected object)
            if hasattr(result, 'masks') and result.masks is not None:
                segmentation_masks = result.masks.data.cpu().numpy()  # Masks as NumPy array

                # Convert masks to binary (if they aren't already)
                binary_mask = np.sum(segmentation_masks, axis=0)  # Combine all masks

                # Apply threshold to ensure we have a proper binary mask
                _, binary_mask = cv2.threshold(binary_mask, 0.5, 1, cv2.THRESH_BINARY)

                # Apply morphological operations (close and open) to separate peanuts
                kernel = np.ones((5, 5), np.uint8)
                morphed_mask = cv2.morphologyEx(binary_mask.astype(np.uint8), cv2.MORPH_CLOSE, kernel)  # Close small gaps
                morphed_mask = cv2.morphologyEx(morphed_mask, cv2.MORPH_OPEN, kernel)  # Remove small noise

                # Find connected components in the morphed mask
                num_labels, labels = cv2.connectedComponents(morphed_mask)

                # Initialize a random color map for each detected peanut
                colormap = np.random.randint(0, 255, size=(num_labels, 3), dtype=np.uint8)

                # Create a 3-channel image for visualization (RGB)
                vis_image = np.zeros((binary_mask.shape[0], binary_mask.shape[1], 3), dtype=np.uint8)

                # Count valid peanuts (labels with a sufficient area)
                num_peanuts = 0
                for label in range(1, num_labels):  # Skip the background (label 0)
                    # Extract the mask for each individual peanut
                    individual_peanut_mask = (labels == label).astype(np.uint8)

                    # Calculate area
                    area = np.sum(individual_peanut_mask)
                    if area > MIN_AREA:  # Only consider contours with sufficient area
                        # Assign a unique color to the mask for visualization
                        color = colormap[label]
                        vis_image[individual_peanut_mask == 1] = color  # Assign color to the corresponding pixels

                        num_peanuts += 1

                # Show the image with detected peanuts
                plt.figure(figsize=(10, 10))
                plt.imshow(vis_image)
                plt.title(f"Detected Peanuts: {num_peanuts}")
                plt.show()

                # Save the result to the output folder
                output_image_path = os.path.join(output_folder, f"labeled_{filename}")
                cv2.imwrite(output_image_path, vis_image)
                print(f"Saved labeled image to: {output_image_path}")

            else:
                print("No segmentation masks found in the result.")

import os
import numpy as np
import cv2
from PIL import Image
import matplotlib.pyplot as plt
from ultralytics import YOLO

# Define the folder containing images and the output folder
image_folder = "/content/gdrive/MyDrive/Peanut_AF/show"  # Your folder containing images
output_folder = "/content/gdrive/MyDrive/Peanut_AF/labeled_results"  # Folder to save labeled results

# Create the output folder if it doesn't exist
os.makedirs(output_folder, exist_ok=True)

# Load the YOLO model
model_path = "/content/gdrive/MyDrive/Peanut_AF/train/train/weights/best.pt"
model = YOLO(model_path)

# Process each image in the image folder
for filename in os.listdir(image_folder):
    if filename.lower().endswith(('.png', '.jpg', '.jpeg')):  # Process only image files
        image_path = os.path.join(image_folder, filename)
        print(f"Processing: {image_path}")

        # Run inference on the image to get the segmentation masks
        results = model.predict(source=image_path)

        for result in results:
            # Extract the masks (each mask corresponds to a detected object)
            if hasattr(result, 'masks') and result.masks is not None:
                segmentation_masks = result.masks.data.cpu().numpy()  # Masks as NumPy array

                # Convert masks to a single binary mask
                binary_mask = np.sum(segmentation_masks, axis=0) > 0  # Combine and threshold




                # Visualize detected instances
                plt.figure(figsize=(10, 10))
                plt.imshow(binary_mask, cmap='gray')
                plt.title(f"Detected Instances")
                plt.show()

                # Optionally save the binary mask for further processing
                output_image_path = os.path.join(output_folder, f"mask_{filename}")
                cv2.imwrite(output_image_path, binary_mask.astype(np.uint8) * 255)
                print(f"Saved mask to: {output_image_path}")

        else:
            print("No segmentation masks found in the result.")

import os
import numpy as np
import cv2
from PIL import Image
import matplotlib.pyplot as plt
from ultralytics import YOLO

# Define the folder containing images and the output folder
image_folder = "/content/gdrive/MyDrive/Peanut_AF/show"  # Your folder containing images
output_folder = "/content/gdrive/MyDrive/Peanut_AF/labeled_results"  # Folder to save labeled results

# Create the output folder if it doesn't exist
os.makedirs(output_folder, exist_ok=True)

# Load the YOLO model
model_path = "/content/gdrive/MyDrive/Peanut_AF/train/train/weights/best.pt"
model = YOLO(model_path)

def visualize_instances_with_colors(image, masks):
    """
    Visualize detected instances with unique colors for each mask.

    Args:
    - image (numpy array): Original image.
    - masks (numpy array): Array of segmentation masks.
    """
    # Create a blank canvas to overlay masks
    colored_masks = np.zeros_like(image, dtype=np.uint8)

    # Generate random colors for each instance
    np.random.seed(42)  # For reproducibility
    colors = [np.random.randint(0, 255, size=3, dtype=np.uint8) for _ in range(masks.shape[0])]

    # Resize masks to match the dimensions of the original image
    resized_masks = [cv2.resize(mask, (image.shape[1], image.shape[0]), interpolation=cv2.INTER_NEAREST) for mask in masks]

    # Overlay each mask with its corresponding color
    for i, mask in enumerate(resized_masks):
        colored_masks[mask > 0] = colors[i]

    # Combine the original image and colored masks
    blended_image = cv2.addWeighted(image, 0.6, colored_masks, 0.4, 0)

    # Plot the blended image
    plt.figure(figsize=(10, 10))
    plt.imshow(cv2.cvtColor(blended_image, cv2.COLOR_BGR2RGB))
    plt.title("Detected Instances with Unique Colors")
    plt.axis("off")
    plt.show()

# Process each image in the image folder
for filename in os.listdir(image_folder):
    if filename.lower().endswith(('.png', '.jpg', '.jpeg')):  # Process only image files
        image_path = os.path.join(image_folder, filename)
        print(f"Processing: {image_path}")

        # Load the image
        original_image = cv2.imread(image_path)
        original_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)  # Convert to RGB for visualization

        # Run inference on the image to get the segmentation masks
        results = model.predict(source=image_path)

        for result in results:
            # Extract the masks (each mask corresponds to a detected object)
            if hasattr(result, 'masks') and result.masks is not None:
                segmentation_masks = result.masks.data.cpu().numpy()  # Masks as NumPy array

                # Visualize instances with unique colors
                visualize_instances_with_colors(original_image, segmentation_masks)

                # Optionally save the binary mask for further processing
                for i, mask in enumerate(segmentation_masks):
                    resized_mask = cv2.resize(mask, (original_image.shape[1], original_image.shape[0]), interpolation=cv2.INTER_NEAREST)
                    output_mask_path = os.path.join(output_folder, f"mask_{i}_{filename}")
                    cv2.imwrite(output_mask_path, resized_mask.astype(np.uint8) * 255)
                    print(f"Saved individual mask to: {output_mask_path}")
            else:
                print("No segmentation masks found in the result.")

import os
import numpy as np
import cv2
from PIL import Image
import matplotlib.pyplot as plt
from ultralytics import YOLO

# Define the folder containing images and the output folder
image_folder = "/content/gdrive/MyDrive/Peanut_AF/show"  # Your folder containing images
output_folder = "/content/gdrive/MyDrive/Peanut_AF/labeled_results"  # Folder to save labeled results
mask_only_folder = "/content/gdrive/MyDrive/Peanut_AF/mask_only_results"  # Folder to save mask-only results

# Create the output folders if they don't exist
os.makedirs(output_folder, exist_ok=True)
os.makedirs(mask_only_folder, exist_ok=True)

# Load the YOLO model
model_path = "/content/gdrive/MyDrive/Peanut_AF/train/train/weights/best.pt"
model = YOLO(model_path)

def visualize_instances_with_colors(image, masks):
    """
    Visualize detected instances with unique colors for each mask.

    Args:
    - image (numpy array): Original image.
    - masks (numpy array): Array of segmentation masks.
    """
    # Create a blank canvas to overlay masks
    colored_masks = np.zeros_like(image, dtype=np.uint8)

    # Generate random colors for each instance
    np.random.seed(42)  # For reproducibility
    colors = [np.random.randint(0, 255, size=3, dtype=np.uint8) for _ in range(masks.shape[0])]

    # Resize masks to match the dimensions of the original image
    resized_masks = [cv2.resize(mask, (image.shape[1], image.shape[0]), interpolation=cv2.INTER_NEAREST) for mask in masks]

    # Overlay each mask with its corresponding color
    for i, mask in enumerate(resized_masks):
        colored_masks[mask > 0] = colors[i]

    # Combine the original image and colored masks
    blended_image = cv2.addWeighted(image, 0.6, colored_masks, 0.4, 0)

    # Plot the blended image
    plt.figure(figsize=(10, 10))
    plt.imshow(cv2.cvtColor(blended_image, cv2.COLOR_BGR2RGB))
    plt.title("Detected Instances with Unique Colors")
    plt.axis("off")
    plt.show()

def visualize_mask_only(masks, image_shape, save_path=None):
    """
    Visualize a combined mask-only image with all detected objects.

    Args:
    - masks (numpy array): Array of segmentation masks.
    - image_shape (tuple): Shape of the original image (height, width).
    - save_path (str): Path to save the mask-only image (optional).
    """
    # Create a blank mask canvas
    combined_mask = np.zeros(image_shape[:2], dtype=np.uint8)

    # Resize and combine all masks into one
    resized_masks = [cv2.resize(mask, (image_shape[1], image_shape[0]), interpolation=cv2.INTER_NEAREST) for mask in masks]
    for mask in resized_masks:
        combined_mask[mask > 0] = 255  # Set mask pixels to white

    # Display the mask-only image
    plt.figure(figsize=(10, 10))
    plt.imshow(combined_mask, cmap='gray')
    plt.title("Combined Mask-Only Image")
    plt.axis("off")
    plt.show()

    # Save the mask-only image if save_path is provided
    if save_path:
        cv2.imwrite(save_path, combined_mask)
        print(f"Saved combined mask-only image to: {save_path}")

# Process each image in the image folder
for filename in os.listdir(image_folder):
    if filename.lower().endswith(('.png', '.jpg', '.jpeg')):  # Process only image files
        image_path = os.path.join(image_folder, filename)
        print(f"Processing: {image_path}")

        # Load the image
        original_image = cv2.imread(image_path)
        original_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)  # Convert to RGB for visualization

        # Run inference on the image to get the segmentation masks
        results = model.predict(source=image_path)

        for result in results:
            # Extract the masks (each mask corresponds to a detected object)
            if hasattr(result, 'masks') and result.masks is not None:
                segmentation_masks = result.masks.data.cpu().numpy()  # Masks as NumPy array

                # Visualize instances with unique colors
                visualize_instances_with_colors(original_image, segmentation_masks)

                # Visualize and save the mask-only image
                mask_only_path = os.path.join(mask_only_folder, f"mask_only_{filename}")
                visualize_mask_only(segmentation_masks, original_image.shape, save_path=mask_only_path)

                # Optionally save each individual resized mask
                for i, mask in enumerate(segmentation_masks):
                    resized_mask = cv2.resize(mask, (original_image.shape[1], original_image.shape[0]), interpolation=cv2.INTER_NEAREST)
                    output_mask_path = os.path.join(output_folder, f"mask_{i}_{filename}")
                    cv2.imwrite(output_mask_path, resized_mask.astype(np.uint8) * 255)
                    print(f"Saved individual mask to: {output_mask_path}")
            else:
                print("No segmentation masks found in the result.")

import os
import numpy as np
import cv2
from PIL import Image
import matplotlib.pyplot as plt
from ultralytics import YOLO

# Define the folder containing images and the output folder
image_folder = "/content/gdrive/MyDrive/Peanut_AF/show"  # Your folder containing images
output_folder = "/content/gdrive/MyDrive/Peanut_AF/labeled_results"  # Folder to save labeled results
mask_only_folder = "/content/gdrive/MyDrive/Peanut_AF/mask_only_results"  # Folder to save mask-only results
colored_mask_folder = "/content/gdrive/MyDrive/Peanut_AF/colored_mask_results"  # Folder to save colored mask results

# Create the output folders if they don't exist
os.makedirs(output_folder, exist_ok=True)
os.makedirs(mask_only_folder, exist_ok=True)
os.makedirs(colored_mask_folder, exist_ok=True)

# Load the YOLO model
model_path = "/content/gdrive/MyDrive/Peanut_AF/train/train/weights/best.pt"
model = YOLO(model_path)

def visualize_instances_with_colors(image, masks):
    """
    Visualize detected instances with unique colors for each mask.

    Args:
    - image (numpy array): Original image.
    - masks (numpy array): Array of segmentation masks.
    """
    # Create a blank canvas to overlay masks
    colored_masks = np.zeros_like(image, dtype=np.uint8)

    # Generate random colors for each instance
    np.random.seed(42)  # For reproducibility
    colors = [np.random.randint(0, 255, size=3, dtype=np.uint8) for _ in range(masks.shape[0])]

    # Resize masks to match the dimensions of the original image
    resized_masks = [cv2.resize(mask, (image.shape[1], image.shape[0]), interpolation=cv2.INTER_NEAREST) for mask in masks]

    # Overlay each mask with its corresponding color
    for i, mask in enumerate(resized_masks):
        colored_masks[mask > 0] = colors[i]

    # Combine the original image and colored masks
    blended_image = cv2.addWeighted(image, 0.6, colored_masks, 0.4, 0)

    # Plot the blended image
    plt.figure(figsize=(10, 10))
    plt.imshow(cv2.cvtColor(blended_image, cv2.COLOR_BGR2RGB))
    plt.title("Detected Instances with Unique Colors")
    plt.axis("off")
    plt.show()

def visualize_colored_masks(masks, image_shape, save_path=None):
    """
    Visualize masks of different instances using unique colors.

    Args:
    - masks (numpy array): Array of segmentation masks.
    - image_shape (tuple): Shape of the original image (height, width, channels).
    - save_path (str): Path to save the colored mask visualization (optional).
    """
    # Create a blank canvas for the colored masks
    colored_mask_image = np.zeros(image_shape, dtype=np.uint8)

    # Generate random colors for each instance
    np.random.seed(42)  # For reproducibility
    colors = [np.random.randint(0, 255, size=3, dtype=np.uint8) for _ in range(masks.shape[0])]

    # Resize and colorize each mask
    resized_masks = [cv2.resize(mask, (image_shape[1], image_shape[0]), interpolation=cv2.INTER_NEAREST) for mask in masks]
    for i, mask in enumerate(resized_masks):
        colored_mask_image[mask > 0] = colors[i]

    # Display the colored masks
    plt.figure(figsize=(10, 10))
    plt.imshow(cv2.cvtColor(colored_mask_image, cv2.COLOR_BGR2RGB))
    plt.title("Colored Masks for Different Instances")
    plt.axis("off")
    plt.show()

    # Save the colored mask visualization if save_path is provided
    if save_path:
        cv2.imwrite(save_path, colored_mask_image)
        print(f"Saved colored mask visualization to: {save_path}")

# Process each image in the image folder
for filename in os.listdir(image_folder):
    if filename.lower().endswith(('.png', '.jpg', '.jpeg')):  # Process only image files
        image_path = os.path.join(image_folder, filename)
        print(f"Processing: {image_path}")

        # Load the image
        original_image = cv2.imread(image_path)
        original_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)  # Convert to RGB for visualization

        # Run inference on the image to get the segmentation masks
        results = model.predict(source=image_path)

        for result in results:
            # Extract the masks (each mask corresponds to a detected object)
            if hasattr(result, 'masks') and result.masks is not None:
                segmentation_masks = result.masks.data.cpu().numpy()  # Masks as NumPy array

                # Visualize instances with unique colors
                visualize_instances_with_colors(original_image, segmentation_masks)

                # Visualize and save the mask-only image
                mask_only_path = os.path.join(mask_only_folder, f"mask_only_{filename}")
                visualize_mask_only(segmentation_masks, original_image.shape, save_path=mask_only_path)

                # Visualize and save the colored mask visualization
                colored_mask_path = os.path.join(colored_mask_folder, f"colored_masks_{filename}")
                visualize_colored_masks(segmentation_masks, original_image.shape, save_path=colored_mask_path)

                # Optionally save each individual resized mask
                for i, mask in enumerate(segmentation_masks):
                    resized_mask = cv2.resize(mask, (original_image.shape[1], original_image.shape[0]), interpolation=cv2.INTER_NEAREST)
                    output_mask_path = os.path.join(output_folder, f"mask_{i}_{filename}")
                    cv2.imwrite(output_mask_path, resized_mask.astype(np.uint8) * 255)
                    print(f"Saved individual mask to: {output_mask_path}")
            else:
                print("No segmentation masks found in the result.")

import os
from PIL import Image
from ultralytics import YOLO

# Define the model path
model_path = "/content/gdrive/MyDrive/Peanut_AF/train/train/weights/best.pt"

# Load the model
model = YOLO(model_path)

# Define the folder containing images
image_folder = "/content/gdrive/MyDrive/Peanut_AF/show"

# Process each image
for filename in os.listdir(image_folder):
    if filename.lower().endswith(('.png', '.jpg', '.jpeg')):
        image_path = os.path.join(image_folder, filename)
        print(f"Processing: {image_path}")

        # Load and process the image
        image = Image.open(image_path)
        results = model.predict(source=image_path)
        for result in results:
            result.show()

import cv2
import numpy as np
import matplotlib.pyplot as plt


def save_combined_binary_mask(binary_mask, save_path):
    """
    Save the binary mask of all connected components combined.

    Args:
    - binary_mask (numpy array): Combined binary mask (H x W).
    - save_path (str): Filepath to save the binary mask.
    """
    cv2.imwrite(save_path, (binary_mask * 255).astype(np.uint8))  # Save as 8-bit grayscale
    print(f"Saved combined binary mask to: {save_path}")

def visualize_connected_components(labels, image_shape, save_path=None):
    """
    Visualize connected components with unique colors.

    Args:
    - labels (numpy array): Labeled array of connected components (H x W).
    - image_shape (tuple): Shape of the original image (H, W, 3).
    - save_path (str): Path to save the output image (optional).
    """
    # Create a blank image for visualization with 3 color channels
    H, W = labels.shape
    connected_mask_image = np.zeros((H, W, 3), dtype=np.uint8)

    # Assign random colors to each unique label
    unique_labels = np.unique(labels)
    np.random.seed(42)  # Fixed seed for reproducible colors
    colors = {label: np.random.randint(0, 255, size=3, dtype=np.uint8) for label in unique_labels if label != 0}

    # Apply colors to the labeled components
    for label_id, color in colors.items():
        connected_mask_image[labels == label_id] = color

    # Save the visualization if a path is provided
    if save_path:
        cv2.imwrite(save_path, cv2.cvtColor(connected_mask_image, cv2.COLOR_RGB2BGR))
        print(f"Saved connected component visualization to: {save_path}")

    # Display the connected component visualization
    plt.figure(figsize=(10, 10))
    plt.imshow(cv2.cvtColor(connected_mask_image, cv2.COLOR_BGR2RGB))
    plt.title("Connected Components (Unique Colors)")
    plt.axis("off")
    plt.show()


def overlay_connected_components(image, labels, save_path=None):
    """
    Overlay connected components on the original image with unique colors.

    Args:
    - image (numpy array): Original image (H x W x 3).
    - labels (numpy array): Labeled array of connected components (H x W).
    - save_path (str): Path to save the output image (optional).
    """
    # Ensure the labels have the same dimensions as the original image
    H, W = image.shape[:2]

    # Resize labels to match the original image size if necessary
    if labels.shape != (H, W):
        labels = cv2.resize(labels, (W, H), interpolation=cv2.INTER_NEAREST)

    # Create an empty overlay image
    overlay = np.zeros_like(image, dtype=np.uint8)

    # Generate unique random colors for each label
    unique_labels = np.unique(labels)
    np.random.seed(42)  # Fixed seed for reproducible colors
    colors = {label: np.random.randint(0, 255, size=3, dtype=np.uint8) for label in unique_labels if label != 0}

    # Apply the color to each connected component in the labels
    for label_id, color in colors.items():
        overlay[labels == label_id] = color

    # Blend the original image with the overlay
    blended_image = cv2.addWeighted(image, 0.7, overlay, 0.3, 0)

    # Save the blended image if a save path is provided
    if save_path:
        cv2.imwrite(save_path, cv2.cvtColor(blended_image, cv2.COLOR_RGB2BGR))
        print(f"Saved overlay visualization to: {save_path}")

    # Display the result
    plt.figure(figsize=(10, 10))
    plt.imshow(cv2.cvtColor(blended_image, cv2.COLOR_BGR2RGB))
    plt.title("Overlay of Connected Components")
    plt.axis("off")
    plt.show()


# Process each image in the image folder
for filename in os.listdir(image_folder):
    if filename.lower().endswith(('.png', '.jpg', '.jpeg')):  # Process only image files
        image_path = os.path.join(image_folder, filename)
        print(f"Processing: {image_path}")

        # Load the image
        original_image = cv2.imread(image_path)
        original_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)  # Convert to RGB for visualization

        # Run inference on the image to get the segmentation masks
        results = model.predict(source=image_path)

        for result in results:
            if hasattr(result, 'masks') and result.masks is not None:
                # Get the masks from the result
                segmentation_masks = result.masks.data.cpu().numpy()  # Masks as NumPy array

                # Combine all instance masks into a single binary mask
                combined_mask = np.sum(segmentation_masks, axis=0) > 0  # Binary mask

                # Save the binary mask
                binary_mask_path = os.path.join(connected_mask_folder, f"binary_{filename}")
                save_combined_binary_mask(combined_mask, binary_mask_path)

                # Apply distance transform and identify local maxima
                distance = distance_transform_edt(combined_mask)
                local_maxima = distance > np.percentile(distance, 90)  # Threshold for maxima
                markers = label(local_maxima)[0]

                # Ensure markers and mask have compatible shapes
                markers = markers.reshape(combined_mask.shape)

                # Perform watershed segmentation
                labels = watershed(-distance, markers, mask=combined_mask)

                # Save connected components visualization
                connected_mask_path = os.path.join(connected_mask_folder, f"connected_{filename}")
                visualize_connected_components(labels, original_image.shape, save_path=connected_mask_path)

                # Overlay connected components on the original image
                overlay_path = os.path.join(output_folder, f"overlay_{filename}")
                overlay_connected_components(original_image, labels, save_path=overlay_path)

import cv2
import numpy as np
import os
import matplotlib.pyplot as plt
from scipy.ndimage import distance_transform_edt, label
from skimage.segmentation import watershed

def merge_connected_components(image, labels):
    """
    Merge connected components that are part of the same peanut using morphological operations.

    Args:
    - image (numpy array): Original image (H x W x 3).
    - labels (numpy array): Labeled array of connected components (H x W).

    Returns:
    - merged_labels (numpy array): Merged connected components (H x W).
    """
    # Create a binary mask from the labels (0 for background, 1 for each component)
    mask = np.zeros_like(labels, dtype=np.uint8)
    for label_id in np.unique(labels):
        if label_id != 0:  # Ignore background label
            mask[labels == label_id] = 255

    # Perform morphological closing (dilation followed by erosion) to merge nearby components
    kernel = np.ones((20, 20), np.uint8)  # Adjust size for merging
    closed_mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)

    # Label the connected components after closing
    merged_labels, num_labels = label(closed_mask)

    return merged_labels

def overlay_connected_components(image, labels, save_path=None):
    """
    Overlay connected components on the original image with unique colors.

    Args:
    - image (numpy array): Original image (H x W x 3).
    - labels (numpy array): Labeled array of connected components (H x W).
    - save_path (str): Path to save the output image (optional).
    """
    # Ensure the labels have the same dimensions as the original image
    H, W = image.shape[:2]

    # Resize labels to match the original image size if necessary
    if labels.shape != (H, W):
        labels = cv2.resize(labels, (W, H), interpolation=cv2.INTER_NEAREST)

    # Merge connected components (if needed)
    merged_labels = merge_connected_components(image, labels)

    # Create an empty overlay image
    overlay = np.zeros_like(image, dtype=np.uint8)

    # Generate unique random colors for each label
    unique_labels = np.unique(merged_labels)
    np.random.seed(42)  # Fixed seed for reproducible colors
    colors = {label: np.random.randint(0, 255, size=3, dtype=np.uint8) for label in unique_labels if label != 0}

    # Apply the color to each connected component in the labels
    for label_id, color in colors.items():
        overlay[merged_labels == label_id] = color

    # Blend the original image with the overlay
    blended_image = cv2.addWeighted(image, 0.7, overlay, 0.3, 0)

    # Save the blended image if a save path is provided
    if save_path:
        cv2.imwrite(save_path, cv2.cvtColor(blended_image, cv2.COLOR_RGB2BGR))
        print(f"Saved overlay visualization to: {save_path}")

    # Display the result
    plt.figure(figsize=(10, 10))
    plt.imshow(cv2.cvtColor(blended_image, cv2.COLOR_BGR2RGB))
    plt.title("Overlay of Connected Components (Merged Peanuts)")
    plt.axis("off")
    plt.show()

def save_combined_binary_mask(mask, output_path):
    """
    Save the combined binary mask to the specified path.

    Args:
    - mask (numpy array): The binary mask (H x W).
    - output_path (str): Path to save the output binary mask.
    """
    cv2.imwrite(output_path, (mask * 255).astype(np.uint8))  # Convert to 0-255 scale and save
    print(f"Saved binary mask to: {output_path}")

# Example image folder and output folder
image_folder = "/content/gdrive/MyDrive/Peanut_AF/show"
output_folder = "/content/gdrive/MyDrive/Peanut_AF/labeled_results"
connected_mask_folder = "/content/gdrive/MyDrive/Peanut_AF/connected_mask_results"

# Process each image in the image folder
for filename in os.listdir(image_folder):
    if filename.lower().endswith(('.png', '.jpg', '.jpeg')):  # Process only image files
        image_path = os.path.join(image_folder, filename)
        print(f"Processing: {image_path}")

        # Load the image
        original_image = cv2.imread(image_path)
        original_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB)  # Convert to RGB for visualization

        # Run inference on the image to get the segmentation masks
        results = model.predict(source=image_path)

        for result in results:
            if hasattr(result, 'masks') and result.masks is not None:
                # Get the masks from the result
                segmentation_masks = result.masks.data.cpu().numpy()  # Masks as NumPy array

                # Combine all instance masks into a single binary mask
                combined_mask = np.sum(segmentation_masks, axis=0) > 0  # Binary mask

                # Save the binary mask
                binary_mask_path = os.path.join(connected_mask_folder, f"binary_{filename}")
                save_combined_binary_mask(combined_mask, binary_mask_path)

                # Apply distance transform and identify local maxima
                distance = distance_transform_edt(combined_mask)
                local_maxima = distance > np.percentile(distance, 95)  # Threshold for maxima
                markers = label(local_maxima)[0]

                # Ensure markers and mask have compatible shapes
                markers = markers.reshape(combined_mask.shape)

                # Perform watershed segmentation
                labels = watershed(-distance, markers, mask=combined_mask)

                # Save connected components visualization
                connected_mask_path = os.path.join(connected_mask_folder, f"connected_{filename}")
                visualize_connected_components(labels, original_image.shape, save_path=connected_mask_path)

                # Overlay connected components on the original image
                overlay_path = os.path.join(output_folder, f"overlay_{filename}")
                overlay_connected_components(original_image, labels, save_path=overlay_path)

import os
import cv2
import numpy as np
from PIL import Image
from ultralytics import YOLO
from google.colab.patches import cv2_imshow
import matplotlib.pyplot as plt

# Define grades
grades = {
    0: (0, 0, "Grade 0"),
    1: (0, 10, "Grade 1"),
    2: (10, 20, "Grade 2"),
    3: (20, 50, "Grade 3"),
    4: (50, 80, "Grade 4"),
    5: (80, 100, "Grade 5")
}

# Define paths
model_path = "/content/gdrive/MyDrive/Peanut_AF/train/train/weights/best.pt"
output_folder = "/content/gdrive/MyDrive/Peanut_AF/results"
image_folder = "/content/gdrive/MyDrive/Peanut_AF/show"

# Load the YOLO model
model = YOLO(model_path)

# Create output folder if it doesn't exist
os.makedirs(output_folder, exist_ok=True)

# Initialize grade counts
grade_counts = {0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0}
N = 0  # Total number of peanuts

# Generate a color map from Matplotlib's 'cool' palette
colormap = plt.cm.get_cmap('cool', 6)
colormap = [tuple(int(c * 255) for c in colormap(i)[:3]) for i in range(6)]

# Process each image in the image folder
for filename in os.listdir(image_folder):
    if filename.lower().endswith(('.png', '.jpg', '.jpeg')):

        image_path = os.path.join(image_folder, filename)
        print(f"Processing: {image_path}")

        # Load the original image
        image = Image.open(image_path)
        original_image = np.array(image)

        # Perform inference with the YOLO model
        results = model.predict(source=image_path)

        for result in results:
            if hasattr(result, 'masks') and result.masks is not None:
                # Extract segmentation masks and class labels
                segmentation_masks = result.masks.data.cpu().numpy()  # Masks as NumPy array
                classes = result.boxes.cls.cpu().numpy()  # Class indices for each instance

                # Rescale masks to original image size
                rescaled_masks = []
                for mask in segmentation_masks:
                    rescaled_mask = cv2.resize(mask, (original_image.shape[1], original_image.shape[0]),
                                               interpolation=cv2.INTER_LINEAR)
                    rescaled_masks.append(rescaled_mask)

                # Separate masks for AF-Peanut and Peanut
                af_peanut_mask = np.zeros(original_image.shape[:2], dtype=np.uint8)
                peanut_mask = np.zeros(original_image.shape[:2], dtype=np.uint8)

                for mask, cls in zip(rescaled_masks, classes):
                    if cls == 0:  # AF-Peanut
                        af_peanut_mask = np.logical_or(af_peanut_mask, mask).astype(np.uint8)
                    elif cls == 1:  # Peanut
                        peanut_mask = np.logical_or(peanut_mask, mask).astype(np.uint8)

                # Combine both masks to identify distinct peanuts
                combined_mask = np.logical_or(af_peanut_mask, peanut_mask).astype(np.uint8)

                # Perform connected components analysis to identify individual peanuts
                num_labels, labels = cv2.connectedComponents(combined_mask)

                # Visualize individual peanuts
                vis_image = original_image.copy()
                for i in range(1, num_labels):  # Skip background (label 0)
                    individual_peanut_mask = (labels == i).astype(np.uint8)

                    # Calculate mold percentage
                    af_area = np.sum(np.logical_and(individual_peanut_mask, af_peanut_mask))
                    total_area = np.sum(individual_peanut_mask)

                    if total_area > 0:
                        mold_percentage = (af_area / total_area) * 100

                        # Determine grade and color
                        for grade, (low, high, label) in grades.items():
                            if low <= mold_percentage <= high:
                                grade_label = label
                                color = colormap[grade]
                                grade_counts[grade] += 1
                                N += 1
                                break

                        # Visualize peanut mask with contours
                        contours, _ = cv2.findContours(individual_peanut_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                        cv2.drawContours(vis_image, contours, -1, color, 2)

                        # Add grade and percentage text
                        if contours:
                            x, y, w, h = cv2.boundingRect(contours[0])
                            text = f"{grade_label} ({mold_percentage:.1f}%)"
                            cv2.putText(vis_image, text, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), 2, cv2.LINE_AA)  # Shadow
                            cv2.putText(vis_image, text, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 1, cv2.LINE_AA)

                # Calculate Infection Index
                if N > 0:
                    infection_index = ((0.1 * grade_counts[1] + 0.2 * grade_counts[2] + 0.5 * grade_counts[3] +
                                        0.8 * grade_counts[4] + 1 * grade_counts[5]) / N) * 100
                    infection_text = f"Infection Index:\n{infection_index:.2f}%"

                    # Font settings
                    font = cv2.FONT_HERSHEY_COMPLEX
                    font_scale = 0.8
                    font_thickness = 2
                    line_spacing = 10

                    # Split the text into two lines
                    lines = infection_text.split("\n")
                    text_size_line1 = cv2.getTextSize(lines[0], font, font_scale, font_thickness)[0]
                    text_size_line2 = cv2.getTextSize(lines[1], font, font_scale, font_thickness)[0]

                    # Calculate the total height of the text block
                    total_text_height = text_size_line1[1] + text_size_line2[1] + line_spacing

                    # Draw text on the image
                    text_x = 20
                    text_y = vis_image.shape[0] - 20

                    # Draw the infection index text
                    cv2.putText(vis_image, lines[0], (text_x, text_y - total_text_height + text_size_line1[1]), font, font_scale, (122, 9, 255), font_thickness, cv2.LINE_AA)
                    cv2.putText(vis_image, lines[1], (text_x, text_y), font, font_scale, (122, 9, 255), font_thickness, cv2.LINE_AA)

                # # Add the colormap legend
                # legend_width = 280
                # legend_height = vis_image.shape[0]
                # legend = np.ones((legend_height, legend_width, 3), dtype=np.uint8) * 255  # White background

                # Define legend dimensions
                legend_height = 250
                legend_width = vis_image.shape[1]
                legend = np.ones((legend_height, legend_width, 3), dtype=np.uint8) * 255  # White background

                # Create a combined canvas with increased height (image height + legend height)
                combined_height = vis_image.shape[0] + legend_height
                combined_width = vis_image.shape[1]
                combined = np.ones((combined_height, combined_width, 3), dtype=np.uint8) * 255  # White background
              # Populate the legend with color blocks and labels
                y_offset = 10
                for i, (grade, (low, high, label)) in enumerate(grades.items()):
                    row = i // 3
                    col = i % 3
                    y_start = y_offset + row * 80 + col * 30
                    y_end = y_start + 30
                    cv2.rectangle(legend, (10, y_start), (50, y_end), colormap[grade], -1)
                    cv2.putText(legend, label, (60, y_end - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)

                # # Combine the main image and the legend side by side
                # combined_width = vis_image.shape[1] + legend_width
                # combined = np.ones((vis_image.shape[0], combined_width, 3), dtype=np.uint8) * 255  # White canvas
                # # Combine the main image and the legend side by side
                # combined_width = vis_image.shape[1] + legend_width
                # combined = np.ones((vis_image.shape[0], combined_width, 3), dtype=np.uint8) * 255  # White canvas

                # Place the original image and legend side by side
                # combined[:, :vis_image.shape[1], :] = vis_image
                # combined[:, vis_image.shape[1]:, :] = legend
                # Place the visualization image at the top
                combined[:vis_image.shape[0], :, :] = vis_image
                # Place the legend below the visualization image
                combined[vis_image.shape[0]:, :, :] = legend

                # Display the result using OpenCV
                combined_rgb = cv2.cvtColor(combined, cv2.COLOR_BGR2RGB)
                cv2_imshow(combined_rgb)

                # Save the result
                output_path = os.path.join(output_folder, f"{os.path.splitext(filename)[0]}_result.jpg")
                cv2.imwrite(output_path, combined)
                print(f"Result saved at: {output_path}")
            else:
                print("No segmentation masks found in the result.")

import os
import cv2
import numpy as np
from PIL import Image
from ultralytics import YOLO
from google.colab.patches import cv2_imshow
import matplotlib.pyplot as plt
from scipy.ndimage import distance_transform_edt
from skimage.measure import label
from skimage.segmentation import watershed
# Ensure 'label' function is used correctly
from skimage.measure import label as sk_label



# Define grades
grades = {
    0: (0, 0, "Grade 0"),
    1: (0, 10, "Grade 1"),
    2: (10, 20, "Grade 2"),
    3: (20, 50, "Grade 3"),
    4: (50, 80, "Grade 4"),
    5: (80, 100, "Grade 5")
}

# Define paths
model_path = "/content/gdrive/MyDrive/Peanut_AF/train/train/weights/best.pt"
output_folder = "/content/gdrive/MyDrive/Peanut_AF/results"
image_folder = "/content/gdrive/MyDrive/Peanut_AF/show"

# Load the YOLO model
model = YOLO(model_path)

# Create output folder if it doesn't exist
os.makedirs(output_folder, exist_ok=True)

# Initialize grade counts
grade_counts = {0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0}
N = 0  # Total number of peanuts

# Generate a color map from Matplotlib's 'cool' palette
colormap = plt.cm.get_cmap('cool', 6)
colormap = [tuple(int(c * 255) for c in colormap(i)[:3]) for i in range(6)]

# Process each image in the image folder
for filename in os.listdir(image_folder):
    if filename.lower().endswith(('.png', '.jpg', '.jpeg')):
        image_path = os.path.join(image_folder, filename)
        print(f"Processing: {image_path}")

        # Load the original image
        image = Image.open(image_path)
        original_image = np.array(image)

        # Perform inference with the YOLO model
        results = model.predict(source=image_path)

        for result in results:
            if hasattr(result, 'masks') and result.masks is not None:
                # Extract segmentation masks and class labels
                segmentation_masks = result.masks.data.cpu().numpy()
                classes = result.boxes.cls.cpu().numpy()

                # Rescale masks to original image size
                rescaled_masks = []
                for mask in segmentation_masks:
                    rescaled_mask = cv2.resize(mask, (original_image.shape[1], original_image.shape[0]),
                                               interpolation=cv2.INTER_LINEAR)
                    rescaled_masks.append(rescaled_mask)

                # Combine all masks for AF-Peanut and Peanut
                af_peanut_mask = np.zeros(original_image.shape[:2], dtype=np.uint8)
                peanut_mask = np.zeros(original_image.shape[:2], dtype=np.uint8)

                for mask, cls in zip(rescaled_masks, classes):
                    if cls == 0:  # AF-Peanut
                        af_peanut_mask = np.logical_or(af_peanut_mask, mask).astype(np.uint8)
                    elif cls == 1:  # Peanut
                        peanut_mask = np.logical_or(peanut_mask, mask).astype(np.uint8)

                # Combine both masks
                combined_mask = np.logical_or(af_peanut_mask, peanut_mask).astype(np.uint8)


               # Use the renamed 'sk_label' for segmentation
                distance = distance_transform_edt(combined_mask)
                local_maxima = distance > np.percentile(distance, 95)
                markers = sk_label(local_maxima)  # Use 'sk_label' instead of 'label'
                labels = watershed(-distance, markers, mask=combined_mask)

               # Apply distance transform and watershed segmentation
                # distance = distance_transform_edt(combined_mask)
                # local_maxima = distance > np.percentile(distance, 90)
                # markers = label(local_maxima)
                # labels = watershed(-distance, markers, mask=combined_mask)

                # Visualize and classify individual peanuts
                vis_image = original_image.copy()
                for i in range(1, np.max(labels) + 1):  # Skip background (label 0)
                    individual_peanut_mask = (labels == i).astype(np.uint8)

                    # Calculate mold percentage
                    af_area = np.sum(np.logical_and(individual_peanut_mask, af_peanut_mask))
                    total_area = np.sum(individual_peanut_mask)

                    if total_area > 0:
                        mold_percentage = (af_area / total_area) * 100

                        # Determine grade and color
                        for grade, (low, high, label) in grades.items():
                            if low <= mold_percentage <= high:
                                grade_label = label
                                color = colormap[grade]
                                grade_counts[grade] += 1
                                N += 1
                                break

                        # Visualize peanut mask with contours
                        contours, _ = cv2.findContours(individual_peanut_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                        cv2.drawContours(vis_image, contours, -1, color, 2)

                        # Add grade and percentage text
                        if contours:
                            x, y, w, h = cv2.boundingRect(contours[0])
                            text = f"{grade_label} ({mold_percentage:.1f}%)"
                            cv2.putText(vis_image, text, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), 2, cv2.LINE_AA)
                            cv2.putText(vis_image, text, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 1, cv2.LINE_AA)


                # Calculate Infection Index
                if N > 0:
                    infection_index = ((0.1 * grade_counts[1] + 0.2 * grade_counts[2] + 0.5 * grade_counts[3] +
                                        0.8 * grade_counts[4] + 1 * grade_counts[5]) / N) * 100
                    infection_text = f"Infection Index:\n{infection_index:.2f}%"

                    # Font settings
                    font = cv2.FONT_HERSHEY_COMPLEX
                    font_scale = 0.7
                    font_thickness = 2
                    line_spacing = 30
                    cv2.FONT_HERSHEY_COMPLEX

                    # Split the text into two lines
                    lines = infection_text.split("\n")
                    text_x = 20
                    text_y = vis_image.shape[0] - 20

                    # Draw the infection index text
                    cv2.putText(vis_image, lines[0], (text_x, text_y - 20), font, font_scale, (0, 0, 0), font_thickness, cv2.LINE_AA)
                    cv2.putText(vis_image, lines[1], (text_x, text_y), font, font_scale, (122, 9, 255), font_thickness, cv2.LINE_AA)

                # Define legend dimensions
                    legend_height = 160  # Adjust based on the number of grades
                    legend_width = vis_image.shape[1]
                    legend = np.ones((legend_height, legend_width, 3), dtype=np.uint8) * 255  # White background

                    # Populate the legend with color blocks and labels
                    y_offset = 10
                    for i, (grade, (low, high, label)) in enumerate(grades.items()):
                        y_start = y_offset + i * 20  # Spacing between rows
                        x_start = 20  # Start position for the color block
                        x_end = x_start + 30
                        y_end = y_start + 15

                        # Draw color block
                        cv2.rectangle(legend, (x_start, y_start), (x_end, y_end), colormap[grade], -1)


                            # Get count of peanuts for the current grade
                        count = grade_counts.get(grade, 0)

                        # Add grade label with count
                        text = f"{label} ({low}-{high}%) - {count} peanuts"


                        # Add grade label
                        # text = f"{label} ({low}-{high}%)"
                        cv2.putText(legend, text, (x_end + 10, y_end - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)

                    # Create a combined canvas with increased height (image height + legend height)
                    combined_height = vis_image.shape[0] + legend_height
                    combined_width = vis_image.shape[1]
                    combined = np.ones((combined_height, combined_width, 3), dtype=np.uint8) * 255  # White background

                    # Place the visualization image at the top
                    combined[:vis_image.shape[0], :, :] = vis_image

                    # Place the legend below the visualization image
                    combined[vis_image.shape[0]:, :, :] = legend

                    # Display the result using OpenCV
                    combined_rgb = cv2.cvtColor(combined, cv2.COLOR_BGR2RGB)
                    cv2_imshow(combined_rgb)

                    # Save the result
                    output_path = os.path.join(output_folder, f"{os.path.splitext(filename)[0]}_result_with_legend.jpg")
                    cv2.imwrite(output_path, combined)
                    print(f"Result with legend saved at: {output_path}")


                # Display and save the visualization
                output_path = os.path.join(output_folder, f"{os.path.splitext(filename)[0]}_result.jpg")
                cv2.imwrite(output_path, vis_image)
                cv2_imshow(vis_image)
                print(f"Result saved at: {output_path}")

            else:
                print("No segmentation masks found in the result.")

# Initialize grade counts for each image
grade_counts = {0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0}

# Process each image
for filename in os.listdir(image_folder):
    if filename.lower().endswith(('.png', '.jpg', '.jpeg')):

        # Reset the grade counts for the current image
        grade_counts = {0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0}

        image_path = os.path.join(image_folder, filename)
        print(f"Processing: {image_path}")

        # Load the original image
        image = Image.open(image_path)
        original_image = np.array(image)

        # Perform inference with the YOLO model
        results = model.predict(source=image_path)

        for result in results:
            if hasattr(result, 'masks') and result.masks is not None:
                # Extract segmentation masks and class labels
                segmentation_masks = result.masks.data.cpu().numpy()
                classes = result.boxes.cls.cpu().numpy()

                # Rescale masks to original image size
                rescaled_masks = []
                for mask in segmentation_masks:
                    rescaled_mask = cv2.resize(mask, (original_image.shape[1], original_image.shape[0]),
                                               interpolation=cv2.INTER_LINEAR)
                    rescaled_masks.append(rescaled_mask)

                # Combine all masks for AF-Peanut and Peanut
                af_peanut_mask = np.zeros(original_image.shape[:2], dtype=np.uint8)
                peanut_mask = np.zeros(original_image.shape[:2], dtype=np.uint8)

                for mask, cls in zip(rescaled_masks, classes):
                    if cls == 0:  # AF-Peanut
                        af_peanut_mask = np.logical_or(af_peanut_mask, mask).astype(np.uint8)
                    elif cls == 1:  # Peanut
                        peanut_mask = np.logical_or(peanut_mask, mask).astype(np.uint8)

                # Combine both masks
                combined_mask = np.logical_or(af_peanut_mask, peanut_mask).astype(np.uint8)

                # Apply distance transform and watershed segmentation
                distance = distance_transform_edt(combined_mask)
                local_maxima = distance > np.percentile(distance, 95)
                markers = sk_label(local_maxima)  # Use 'sk_label' for segmentation
                labels = watershed(-distance, markers, mask=combined_mask)

                # Visualize and classify individual peanuts
                vis_image = original_image.copy()
                for i in range(1, np.max(labels) + 1):  # Skip background (label 0)
                    individual_peanut_mask = (labels == i).astype(np.uint8)

                    # Calculate mold percentage
                    af_area = np.sum(np.logical_and(individual_peanut_mask, af_peanut_mask))
                    total_area = np.sum(individual_peanut_mask)

                    if total_area > 0:
                        mold_percentage = (af_area / total_area) * 100

                        # Determine grade and color
                        for grade, (low, high, label) in grades.items():
                            if low <= mold_percentage <= high:
                                grade_label = label
                                color = colormap[grade]
                                grade_counts[grade] += 1  # Increment the count for this grade
                                break

                        # Visualize peanut mask with contours
                        contours, _ = cv2.findContours(individual_peanut_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                        cv2.drawContours(vis_image, contours, -1, color, 2)

                        # Add grade and percentage text
                        if contours:
                            x, y, w, h = cv2.boundingRect(contours[0])
                            text = f"{grade_label} ({mold_percentage:.1f}%)"
                            cv2.putText(vis_image, text, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), 2, cv2.LINE_AA)
                            cv2.putText(vis_image, text, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 1, cv2.LINE_AA)

                # Define legend dimensions
                legend_height = 160  # Adjust based on the number of grades
                legend_width = vis_image.shape[1]
                legend = np.ones((legend_height, legend_width, 3), dtype=np.uint8) * 255  # White background

                # Populate the legend with color blocks, labels, and counts
                y_offset = 10
                for i, (grade, (low, high, label)) in enumerate(grades.items()):
                    y_start = y_offset + i * 20  # Spacing between rows
                    x_start = 20  # Start position for the color block
                    x_end = x_start + 30
                    y_end = y_start + 15

                    # Draw color block
                    cv2.rectangle(legend, (x_start, y_start), (x_end, y_end), colormap[grade], -1)

                    # Get count of peanuts for the current grade
                    count = grade_counts.get(grade, 0)

                    # Add grade label with count
                    text = f"{label} ({low}-{high}%) - {count} peanuts"
                    cv2.putText(legend, text, (x_end + 10, y_end - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)

                # Create a combined canvas with increased height (image height + legend height)
                combined_height = vis_image.shape[0] + legend_height
                combined_width = vis_image.shape[1]
                combined = np.ones((combined_height, combined_width, 3), dtype=np.uint8) * 255  # White background

                # Place the visualization image at the top
                combined[:vis_image.shape[0], :, :] = vis_image

                # Place the legend below the visualization image
                combined[vis_image.shape[0]:, :, :] = legend

                # Calculate Infection Index
                if np.sum(list(grade_counts.values())) > 0:
                    N = np.sum(list(grade_counts.values()))
                    infection_index = ((0.1 * grade_counts[1] + 0.2 * grade_counts[2] + 0.5 * grade_counts[3] +
                                        0.8 * grade_counts[4] + 1 * grade_counts[5]) / N) * 100
                    infection_text = f"Infection Index:\n{infection_index:.2f}%"

                    # Font settings for Infection Index
                    font = cv2.FONT_HERSHEY_COMPLEX
                    font_scale = 0.7
                    font_thickness = 2
                    line_spacing = 30

                    # Split the text into two lines
                    lines = infection_text.split("\n")
                    text_x = 400
                    text_y = combined.shape[0] - 100

                    # Draw the infection index text
                    cv2.putText(combined, lines[0], (text_x, text_y - 20), font, font_scale, (0, 0, 0), font_thickness, cv2.LINE_AA)
                    cv2.putText(combined, lines[1], (text_x, text_y), font, font_scale, (122, 9, 255), font_thickness, cv2.LINE_AA)

                # Display the result using OpenCV
                combined_rgb = cv2.cvtColor(combined, cv2.COLOR_BGR2RGB)
                cv2_imshow(combined_rgb)

                # Save the result
                output_path = os.path.join(output_folder, f"{os.path.splitext(filename)[0]}_result_with_legend_and_infection_index.jpg")
                cv2.imwrite(output_path, combined)
                print(f"Result with legend and infection index saved at: {output_path}")

import cv2
import numpy as np
from skimage.segmentation import watershed
from skimage.measure import label as sk_label
from scipy.ndimage import distance_transform_edt
from PIL import Image
import os


# Define paths
model_path = "/content/gdrive/MyDrive/Peanut_AF/train/train/weights/best.pt"
output_folder = "/content/gdrive/MyDrive/Peanut_AF/results"
image_folder = "/content/gdrive/MyDrive/Peanut_AF/show"

# Load the YOLO model
model = YOLO(model_path)

# Create output folder if it doesn't exist
os.makedirs(output_folder, exist_ok=True)

# Initialize grade counts for each image
grade_counts = {0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0}

# Define grades and their respective ranges
grades = {
    0: (0,0, "Grade 0"),
    1: (0, 10, "Grade 1"),
    2: (10, 20, "Grade 2"),
    3: (20, 50, "Grade 3"),
    4: (50, 80, "Grade 4"),
    5: (80, 100, "Grade 5")
}

# Colormap generation
colormap = plt.cm.get_cmap('cool', 6)
colormap = [tuple(int(c * 255) for c in colormap(i)[:3]) for i in range(6)]


output_folder = "output_images"
os.makedirs(output_folder, exist_ok=True)

# Process each image in the folder



for filename in os.listdir(image_folder):
    if filename.lower().endswith(('.png', '.jpg', '.jpeg')):

        # Reset the grade counts for the current image
        grade_counts = {0: 0, 1: 0, 2: 0, 3: 0, 4: 0, 5: 0}

        image_path = os.path.join(image_folder, filename)
        print(f"Processing: {image_path}")

        # Load the original image
        image = Image.open(image_path)
        original_image = np.array(image)

        # Perform inference with the YOLO model (assuming you have the 'model' variable for inference)
        results = model.predict(source=image_path)  # Replace with actual model prediction

        for result in results:
            if not hasattr(result, 'masks') or result.masks is None:
                print(f"No segmentation masks found for image: {filename}")
                continue

            # Extract segmentation masks and class labels
            segmentation_masks = result.masks.data.cpu().numpy()
            classes = result.boxes.cls.cpu().numpy()

            # Rescale masks to original image size
            rescaled_masks = [cv2.resize(mask, (original_image.shape[1], original_image.shape[0]), interpolation=cv2.INTER_LINEAR) for mask in segmentation_masks]

            # Initialize masks for AF-Peanut and Peanut
            af_peanut_mask = np.zeros(original_image.shape[:2], dtype=np.uint8)
            peanut_mask = np.zeros(original_image.shape[:2], dtype=np.uint8)

            for mask, cls in zip(rescaled_masks, classes):
                if cls == 0:  # AF-Peanut
                    af_peanut_mask = np.logical_or(af_peanut_mask, mask).astype(np.uint8)
                elif cls == 1:  # Peanut
                    peanut_mask = np.logical_or(peanut_mask, mask).astype(np.uint8)

            # Combine both masks
            combined_mask = np.logical_or(af_peanut_mask, peanut_mask).astype(np.uint8)

            # Apply distance transform and watershed segmentation
            distance = distance_transform_edt(combined_mask)
            local_maxima = distance > np.percentile(distance, 95)
            markers = sk_label(local_maxima)  # Use 'sk_label' for segmentation
            labels = watershed(-distance, markers, mask=combined_mask)

            # Visualize and classify individual peanuts
            vis_image = original_image.copy()
            for i in range(1, np.max(labels) + 1):  # Skip background (label 0)
                individual_peanut_mask = (labels == i).astype(np.uint8)

                # Calculate mold percentage
                af_area = np.sum(np.logical_and(individual_peanut_mask, af_peanut_mask))
                total_area = np.sum(individual_peanut_mask)

                if total_area > 0:
                    mold_percentage = (af_area / total_area) * 100

                    # Determine grade and color
                    for grade, (low, high, label) in grades.items():
                        if low <= mold_percentage <= high:
                            grade_label = label
                            color = colormap[grade]
                            grade_counts[grade] += 1  # Increment the count for this grade
                            break

                    # Visualize peanut mask with contours
                    contours, _ = cv2.findContours(individual_peanut_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                    cv2.drawContours(vis_image, contours, -1, color, 2)

                    # Add grade and percentage text
                    if contours:
                        x, y, w, h = cv2.boundingRect(contours[0])
                        text = f"{grade_label} ({mold_percentage:.1f}%)"
                        cv2.putText(vis_image, text, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2, cv2.LINE_AA)
                        cv2.putText(vis_image, text, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 1, cv2.LINE_AA)

            # Define legend dimensions
            legend_height = 160
            legend_width = vis_image.shape[1]
            legend = np.ones((legend_height, legend_width, 3), dtype=np.uint8) * 255  # White background

            # Populate the legend with color blocks, labels, and counts
            y_offset = 10
            for i, (grade, (low, high, label)) in enumerate(grades.items()):
                y_start = y_offset + i * 20
                x_start = 20
                x_end = x_start + 30
                y_end = y_start + 15
                cv2.rectangle(legend, (x_start, y_start), (x_end, y_end), colormap[grade], -1)

                count = grade_counts.get(grade, 0)
                text = f"{label} Total: {count} peanut seeds"
                cv2.putText(legend, text, (x_end + 10, y_end - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 1, cv2.LINE_AA)

            # Combine image and legend
            combined_height = vis_image.shape[0] + legend_height
            combined_width = vis_image.shape[1]
            combined = np.ones((combined_height, combined_width, 3), dtype=np.uint8) * 255  # White background

            # Place the visualization image at the top
            combined[:vis_image.shape[0], :, :] = vis_image

            # Place the legend below the visualization image
            combined[vis_image.shape[0]:, :, :] = legend

            # Calculate Infection Index
            if np.sum(list(grade_counts.values())) > 0:
                N = np.sum(list(grade_counts.values()))
                infection_index = ((0.1 * grade_counts[1] + 0.2 * grade_counts[2] + 0.5 * grade_counts[3] +
                                    0.8 * grade_counts[4] + 1 * grade_counts[5]) / N) * 100
                infection_text = f"Infection Index:\n{infection_index:.2f}%"

                # Determine the resistance category
                if infection_index <= 10:
                    resistance = "R (Resistant)"
                    resistance_color = (25,80, 25)  # Green
                elif infection_index <= 25:
                    resistance = "MR (Moderately Resistant)"
                    resistance_color = (25,80, 25)  # Yellow
                elif infection_index <= 50:
                    resistance = "MS (Moderately Susceptible)"
                    resistance_color = (25,80, 25)  # Light Yellow
                elif infection_index <= 75:
                    resistance = "S (Susceptible)"
                    resistance_color = (25,80, 25) # Red
                else:
                    resistance = "HS (Highly Susceptible)"
                    resistance_color = (25,80, 25)  # Blue


                # Infection Index parts
                infection_index_label =  "Infection Index:"
                infection_index_value =  f"{infection_index:.2f}%"
                # Resistance text parts
                resistance_label = "Type: "  # The label
                resistance_value = resistance  # The value (e.g., "R (Resistant)")

                # Font settings
                font = cv2.FONT_HERSHEY_COMPLEX
                font_scale = 0.7
                font_thickness = 2
                line_spacing = 30

                # Text position
                text_x = 500
                text_y = combined.shape[0] - 110

                # Determine text sizes
                padding = 10
                label_width, label_height = cv2.getTextSize(infection_index_label, font, font_scale, font_thickness)[0]
                value_width, value_height = cv2.getTextSize(infection_index_value, font, font_scale, font_thickness)[0]

                # Rectangle dimensions
                rect_width = 431
                rect_height =88
                rect_x_start = text_x - padding
                rect_y_start = text_y - label_height - padding
                rect_x_end = rect_x_start + rect_width
                rect_y_end = rect_y_start + rect_height

                # Draw the rectangle background with gray color
                cv2.rectangle(combined, (rect_x_start, rect_y_start), (rect_x_end, rect_y_end), (200, 200, 200), -1)  # Gray background
                cv2.rectangle(combined, (rect_x_start, rect_y_start), (rect_x_end, rect_y_end), (200, 200, 200), 2)  # Black border

                # Draw the Infection Index label with one color
                cv2.putText(combined, infection_index_label, (text_x, text_y), font, font_scale, (20, 0, 0), font_thickness, cv2.LINE_AA)  # Red

                # Draw the Infection Index value with another color, placed after the label
                cv2.putText(combined, infection_index_value, (text_x + label_width + padding, text_y), font, font_scale, (25, 80, 25), font_thickness, cv2.LINE_AA)  # Green

                # Determine the position for the Resistance text
                resistance_text_x = text_x
                resistance_text_y = text_y + line_spacing

                # Determine text sizes for alignment
                label_width, label_height = cv2.getTextSize(resistance_label, font, font_scale, font_thickness)[0]

                # Draw the Resistance Category text below it with a third color
                # cv2.putText(combined, f"Type:{resistance}", (text_x, text_y + line_spacing), font, font_scale, resistance_color, font_thickness, cv2.LINE_AA)
                cv2.putText(combined, resistance_label, (resistance_text_x, resistance_text_y), font, font_scale, (0, 0, 0), font_thickness, cv2.LINE_AA)  # Red
                # Draw the Resistance value with another color, positioned after the label
                cv2.putText(combined, resistance_value, (resistance_text_x + label_width + 10, resistance_text_y), font, font_scale, resistance_color, font_thickness, cv2.LINE_AA)  # Dynamic resistance color


            # Save the combined image
            output_image_path = os.path.join(output_folder, f"labeled_{filename}")
            cv2.imwrite(output_image_path, combined)
            combined_rgb = cv2.cvtColor(combined, cv2.COLOR_BGR2RGB)
            cv2_imshow(combined_rgb)

            print(f"Saved labeled image: {output_image_path}")

import os
import cv2
import numpy as np
from PIL import Image
from ultralytics import YOLO
from google.colab.patches import cv2_imshow
import matplotlib.pyplot as plt
from scipy.ndimage import distance_transform_edt
from skimage.measure import label as sk_label  # Renaming for clarity
from skimage.segmentation import watershed


# Define grades
grades = {
    0: (0, 0, "Grade 0"),
    1: (0, 10, "Grade 1"),
    2: (10, 20, "Grade 2"),
    3: (20, 50, "Grade 3"),
    4: (50, 80, "Grade 4"),
    5: (80, 100, "Grade 5")
}

# Define paths
model_path = "/content/gdrive/MyDrive/Peanut_AF/train/train/weights/best.pt"
output_folder = "/content/gdrive/MyDrive/Peanut_AF/results"
image_folder = "/content/gdrive/MyDrive/Peanut_AF/show"

# Load the YOLO model
model = YOLO(model_path)

# Create output folder if it doesn't exist
os.makedirs(output_folder, exist_ok=True)

# Define grades
grades = {
    0: (0, 0, "Grade 0"),
    1: (0, 10, "Grade 1"),
    2: (10, 20, "Grade 2"),
    3: (20, 50, "Grade 3"),
    4: (50, 80, "Grade 4"),
    5: (80, 100, "Grade 5")
}

# Paths and model loading
model_path = "/content/gdrive/MyDrive/Peanut_AF/train/train/weights/best.pt"
output_folder = "/content/gdrive/MyDrive/Peanut_AF/results"
image_folder = "/content/gdrive/MyDrive/Peanut_AF/show"
os.makedirs(output_folder, exist_ok=True)
model = YOLO(model_path)

# Colormap generation
colormap = plt.cm.get_cmap('cool', 6)
colormap = [tuple(int(c * 255) for c in colormap(i)[:3]) for i in range(6)]

# Initialize counters
grade_counts = {i: 0 for i in grades}
N = 0  # Total number of peanuts

# Process each image in the image folder
for filename in os.listdir(image_folder):
    if not filename.lower().endswith(('.png', '.jpg', '.jpeg')):
        continue
    image_path = os.path.join(image_folder, filename)
    print(f"Processing: {image_path}")

    # Load and process image
    image = Image.open(image_path)
    original_image = np.array(image)
    results = model.predict(source=image_path)

    for result in results:
        if not hasattr(result, 'masks') or result.masks is None:
            print("No segmentation masks found.")
            continue

        # Segmentation masks and class labels
        segmentation_masks = result.masks.data.cpu().numpy()
        classes = result.boxes.cls.cpu().numpy()

        # Rescale masks to match the original image size
        af_peanut_mask = np.zeros(original_image.shape[:2], dtype=np.uint8)
        peanut_mask = np.zeros(original_image.shape[:2], dtype=np.uint8)
        for mask, cls in zip(segmentation_masks, classes):
            rescaled_mask = cv2.resize(mask, (original_image.shape[1], original_image.shape[0]),
                                       interpolation=cv2.INTER_LINEAR)
            if cls == 0:  # AF-Peanut
                af_peanut_mask = np.logical_or(af_peanut_mask, rescaled_mask).astype(np.uint8)
            elif cls == 1:  # Peanut
                peanut_mask = np.logical_or(peanut_mask, rescaled_mask).astype(np.uint8)

        # Combine masks
        combined_mask = np.logical_or(af_peanut_mask, peanut_mask).astype(np.uint8)

        # Watershed segmentation
        distance = distance_transform_edt(combined_mask)
        local_maxima = distance > np.percentile(distance, 95)
        markers = sk_label(local_maxima)
        labels = watershed(-distance, markers, mask=combined_mask)

        # Visualization and grading
        vis_image = original_image.copy()
        for i in range(1, np.max(labels) + 1):  # Skip background (label 0)
            individual_mask = (labels == i).astype(np.uint8)
            af_area = np.sum(np.logical_and(individual_mask, af_peanut_mask))
            total_area = np.sum(individual_mask)

            if total_area > 0:
                mold_percentage = (af_area / total_area) * 100
                for grade, (low, high, label) in grades.items():
                    if low <= mold_percentage <= high:
                        color = colormap[grade]
                        grade_counts[grade] += 1
                        N += 1
                        break

                # Draw contours
                contours, _ = cv2.findContours(individual_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
                cv2.drawContours(vis_image, contours, -1, color, 2)

                # Annotate the grade
                if contours:
                    x, y, w, h = cv2.boundingRect(contours[0])
                    text = f"{label} ({mold_percentage:.1f}%)"
                    cv2.putText(vis_image, text, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 0), 2, cv2.LINE_AA)
                    cv2.putText(vis_image, text, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 1, cv2.LINE_AA)




    # Add Infection Index to the bottom of the legend
        infection_text = f"Infection Index: {infection_index:.2f}%"
        cv2.putText(legend, infection_text, (20, legend.shape[0] - 20),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 2, cv2.LINE_AA)


                # Create legend
        legend_height = 160
        legend = np.ones((legend_height, vis_image.shape[1], 3), dtype=np.uint8) * 255
        y_offset = 10
        for i, (grade, (low, high, label)) in enumerate(grades.items()):
            y_start = y_offset + i * 20
            x_start = 20
            x_end = x_start + 30
            y_end = y_start + 15
            cv2.rectangle(legend, (x_start, y_start), (x_end, y_end), colormap[grade], -1)
            text = f"{label} ({low}-{high}%)"
            cv2.putText(legend, text, (x_end + 10, y_end - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)

        # Combine visualization and legend
        combined_height = vis_image.shape[0] + legend_height
        combined = np.ones((combined_height, vis_image.shape[1], 3), dtype=np.uint8) * 255
        combined[:vis_image.shape[0], :, :] = vis_image
        combined[vis_image.shape[0]:, :, :] = legend


        # Display and save combined result
        combined_rgb = cv2.cvtColor(combined, cv2.COLOR_BGR2RGB)
        cv2_imshow(combined_rgb)
        output_path = os.path.join(output_folder, f"{os.path.splitext(filename)[0]}_result_with_legend.jpg")
        cv2.imwrite(output_path, combined)
        print(f"Result with legend saved at: {output_path}")


    # Infection Index
    if N > 0:
        infection_index = ((0.1 * grade_counts[1] + 0.2 * grade_counts[2] +
                            0.5 * grade_counts[3] + 0.8 * grade_counts[4] +
                            1.0 * grade_counts[5]) / N) * 100
        print(f"Infection Index: {infection_index:.2f}%")

model_path = "/content/gdrive/MyDrive/Peanut_AF/train/train/weights/best.pt"

# Load the model
model = YOLO(model_path)

# Define the folder containing images
image_folder = "/content/gdrive/MyDrive/Peanut_AF/show"

# Define the destination folder for saving results
output_folder = "/content/gdrive/MyDrive/Peanut_AF/results"
os.makedirs(output_folder, exist_ok=True)  # Create the folder if it doesn't exist

combined_mask = np.sum(mask_array, axis=0)

# Normalize the combined mask to a binary mask
combined_mask = np.clip(combined_mask, 0, 1)

# Show the combined mask
plt.imshow(combined_mask, cmap='gray')
plt.title("Combined Moldy and Unmolded Peanut Areas")
plt.show()

moldy_peanut_count = sum(1 for corn in peanut_areas if corn['mold_area'] / corn['total_area'] > 0.1)

print(f"Number of mold-affected corns: {moldy_peanut_count}")

project.version(dataset.version).deploy(model_type="yolov11-seg", model_path=f"{HOME}/runs/segment/train/")

!pip install inference

import os, random, cv2
import supervision as sv
import IPython
import inference

model_id = project.id.split("/")[1] + "/" + dataset.version
model = inference.get_model(model_id, userdata.get('ROBOFLOW_API_KEY'))

# Location of test set images
test_set_loc = dataset.location + "/test/images/"
test_images = os.listdir(test_set_loc)

# Run inference on 4 random test images, or fewer if fewer images are available
for img_name in random.sample(test_images, min(4, len(test_images))):
    print("Running inference on " + img_name)

    # Load image
    image = cv2.imread(os.path.join(test_set_loc, img_name))

    # Perform inference
    results = model.infer(image)[0]
    detections = sv.Detections.from_inference(results)

    # Annotate boxes and labels
    mask_annotator = sv.MaskAnnotator()
    label_annotator = sv.LabelAnnotator()
    annotated_image = mask_annotator.annotate(scene=image, detections=detections)
    annotated_image = label_annotator.annotate(scene=annotated_image, detections=detections)

    # Display annotated image
    _, ret = cv2.imencode('.jpg', annotated_image)
    i = IPython.display.Image(data=ret)
    IPython.display.display(i)

"""## ðŸ† Congratulations

### Learning Resources

Roboflow has produced many resources that you may find interesting as you advance your knowledge of computer vision:

- [Roboflow Notebooks](https://github.com/roboflow/notebooks): A repository of over 20 notebooks that walk through how to train custom models with a range of model types, from YOLOv7 to SegFormer.
- [Roboflow YouTube](https://www.youtube.com/c/Roboflow): Our library of videos featuring deep dives into the latest in computer vision, detailed tutorials that accompany our notebooks, and more.
- [Roboflow Discuss](https://discuss.roboflow.com/): Have a question about how to do something on Roboflow? Ask your question on our discussion forum.
- [Roboflow Models](https://roboflow.com): Learn about state-of-the-art models and their performance. Find links and tutorials to guide your learning.

### Convert data formats

Roboflow provides free utilities to convert data between dozens of popular computer vision formats. Check out [Roboflow Formats](https://roboflow.com/formats) to find tutorials on how to convert data between formats in a few clicks.

### Connect computer vision to your project logic

[Roboflow Templates](https://roboflow.com/templates) is a public gallery of code snippets that you can use to connect computer vision to your project logic. Code snippets range from sending emails after inference to measuring object distance between detections.
"""